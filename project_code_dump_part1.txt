--- CODE DUMP | PART 1 of 4 ---


================================================================================
# PY FILE: app.py
================================================================================



================================================================================
# PY FILE: debug.py
================================================================================

from src.student_performance.pipeline.training_pipeline import TrainingPipeline
from dotenv import load_dotenv
load_dotenv()

if __name__ == "__main__":
    pipeline = TrainingPipeline()
    pipeline.run_pipeline()
    print("shivaneee!!!")

================================================================================
# PY FILE: main.py
================================================================================

from src.student_performance.pipeline.training_pipeline import TrainingPipeline

if __name__ == "__main__":
    pipeline = TrainingPipeline()
    pipeline.run_pipeline()
    print("shivaneee!!!")

================================================================================
# PY FILE: project_dump.py
================================================================================

import os
import math

EXCLUDE_DIRS = {'.venv', 'venv', '__pycache__', '.github', '.git', '.idea', '.vscode', 'build', 'dist', '.mypy_cache'}
INCLUDE_YAML_FILES = {'config.yaml', 'params.yaml', 'schema.yaml', 'templates.yaml'}
BASE_OUTPUT_FILE = "project_code_dump_part"
SUMMARY_FILE = "project_code_dump_index.txt"
STRUCTURE_FILE = "project_structure.txt"


def is_valid_directory(dirname):
    return not any(part in EXCLUDE_DIRS for part in dirname.split(os.sep))


def print_directory_tree(start_path: str, indent: str = "", exclude_dirs=None, out_lines=None) -> list:
    if exclude_dirs is None:
        exclude_dirs = EXCLUDE_DIRS
    if out_lines is None:
        out_lines = []

    try:
        items = sorted(os.listdir(start_path))
    except PermissionError:
        return out_lines

    for item in items:
        item_path = os.path.join(start_path, item)
        if os.path.isdir(item_path):
            if item in exclude_dirs:
                continue
            out_lines.append(f"{indent}üìÅ {item}/")
            print_directory_tree(item_path, indent + "    ", exclude_dirs, out_lines)
        else:
            out_lines.append(f"{indent}üìÑ {item}")
    return out_lines


def list_target_files(root_dir):
    py_files = []
    yaml_files = []

    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if is_valid_directory(os.path.join(dirpath, d))]
        for filename in filenames:
            full_path = os.path.join(dirpath, filename)
            rel_path = os.path.relpath(full_path, root_dir)

            if filename.endswith('.py'):
                py_files.append((rel_path, full_path))
            elif filename in INCLUDE_YAML_FILES:
                yaml_files.append((rel_path, full_path))

    return sorted(py_files), sorted(yaml_files)


def chunk_list(data, num_chunks):
    chunk_size = math.ceil(len(data) / num_chunks)
    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]


def dump_project_code_in_parts(root_dir='.', num_parts=1):
    py_files, yaml_files = list_target_files(root_dir)
    tree_lines = print_directory_tree(root_dir, out_lines=[])
    total_files = py_files + yaml_files

    if not total_files:
        print("‚ùå No .py or relevant .yaml files found.")
        return

    # Save project structure once
    with open(STRUCTURE_FILE, 'w', encoding='utf-8') as struct_file:
        struct_file.write(f"üì¶ Project Structure of: {os.path.abspath(root_dir)}\n\n")
        struct_file.write("\n".join(tree_lines))
    print(f"‚úÖ Project structure saved to: {os.path.abspath(STRUCTURE_FILE)}")

    file_chunks = chunk_list(total_files, num_parts)
    summary_lines = []

    for i, chunk in enumerate(file_chunks, start=1):
        part_filename = f"{BASE_OUTPUT_FILE}{i}.txt"
        with open(part_filename, 'w', encoding='utf-8') as out_file:
            out_file.write(f"--- CODE DUMP | PART {i} of {num_parts} ---\n\n")

            for rel_path, full_path in chunk:
                summary_lines.append(f"{part_filename}: {rel_path}")
                out_file.write(f"\n{'=' * 80}\n")
                file_type = "PY FILE" if rel_path.endswith('.py') else "YAML FILE"
                out_file.write(f"# {file_type}: {rel_path}\n")
                out_file.write(f"{'=' * 80}\n\n")
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        out_file.write(content.strip() + "\n")
                except Exception as e:
                    out_file.write(f"Error reading {rel_path}: {e}\n")

        print(f"‚úÖ Dumped part {i} to: {os.path.abspath(part_filename)}")

    # Write summary file
    with open(SUMMARY_FILE, 'w', encoding='utf-8') as f:
        f.write("üìÑ File-to-Part Mapping\n\n")
        for line in summary_lines:
            f.write(line + "\n")

    print(f"\nüìù Summary index saved to: {os.path.abspath(SUMMARY_FILE)}")


if __name__ == "__main__":
    ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
    try:
        num_parts = int(input("Enter number of parts to split the dump into: ").strip())
        if num_parts < 1:
            raise ValueError
    except ValueError:
        print("‚ùå Invalid input. Please enter a positive integer.")
    else:
        dump_project_code_in_parts(ROOT_DIR, num_parts)

================================================================================
# PY FILE: project_template.py
================================================================================

import os
from pathlib import Path
import logging

# ==============================
# üîπ LOGGING SETUP
# ==============================

# ‚úÖ Define the directory where logs will be stored
log_dir = "logs"

# ‚úÖ Define the log file name and full path
log_filepath = os.path.join(log_dir, 'directorygen_logs.log')

# ‚úÖ Define the format for log messages
log_format = '[%(asctime)s] - %(levelname)s - %(module)s - %(message)s'

def setup_logging():
    """
    Sets up a custom logger:
    - Creates the `logs/` directory if it doesn't exist.
    - Configures log messages to be written to both a file and the console.
    - Uses append mode (`"a"`) so logs persist across multiple runs.
    - Ensures handlers are not added multiple times.
    - Logger name: `directory_builder` (used for all logging in this script).
    
    Returns:
        logging.Logger: Custom logger instance.
    """

    # ‚úÖ Ensure the log directory exists before creating the log file
    os.makedirs(log_dir, exist_ok=True)

    # ‚úÖ Create a custom logger (separate from the root logger)
    logger = logging.getLogger('directory_builder')

    # ‚úÖ Set the logger level to DEBUG (captures all log levels)
    logger.setLevel(logging.DEBUG)

    # ‚úÖ Prevent adding duplicate handlers
    if not logger.hasHandlers():
        formatter = logging.Formatter(log_format)  # ‚úÖ Define the log message format

        # ‚úÖ Create a File Handler (logs INFO and above)
        file_handler = logging.FileHandler(log_filepath, mode='a')  # Append mode ("a")
        file_handler.setFormatter(formatter)  # Apply the log format

        # ‚úÖ Create a Stream Handler (logs DEBUG and above to console)
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(formatter)  # Apply the log format

        # ‚úÖ Add handlers to the logger
        logger.addHandler(file_handler)
        logger.addHandler(stream_handler)

    return logger  # ‚úÖ Return the configured logger

# ‚úÖ Initialize the logger
logger = setup_logging()



# ==============================
# üîπ PROJECT SETUP
# ==============================

# ‚úÖ Define the project name (used in file paths)
project_name = input("Enter the project name: ")

# ‚úÖ List of files and directories to be created in the project structure
list_of_files = [
    # üîπ GitHub workflows (for CI/CD setup)
    ".github/workflows/.gitkeep",  
    
    # üîπ Source Code Structure
    f"src/{project_name}/__init__.py",  # Main package initializer
    f"src/{project_name}/components/__init__.py",  # Components submodule initializer
    f"src/{project_name}/utils/__init__.py",  # Utilities submodule initializer
    f"src/{project_name}/utils/core.py",  # Core utility functions
    f"src/{project_name}/config/__init__.py",  # Configuration submodule
    f"src/{project_name}/config/configuration.py",  # Configuration handling script
    f"src/{project_name}/pipeline/__init__.py",  # Pipeline processing module
    f"src/{project_name}/entity/__init__.py",  # Entity-related module
    f"src/{project_name}/entity/config_entity.py",  # Configuration entity class
    f"src/{project_name}/constants/__init__.py",  # Constants module

    # üîπ Configuration and Parameter Files
    "config/config.yaml",  # YAML file for configuration settings
    "params.yaml",  # YAML file for parameter tuning
    "schema.yaml",  # YAML file for data schema definition

    # üîπ Project Execution and Deployment
    "main.py",  # Main entry point of the project
    "Dockerfile",  # Dockerfile for containerization
    "setup.py",  # Setup script for packaging
    "requirements.txt",  # Requirements file for Python dependencies

    # üîπ Research and Web Components
    "research/research.ipynb",  # Jupyter notebook for exploratory research
    "templates/index.html",  # HTML template file (for a web component)

    # üîπ Backend API
    "app.py"  # Flask or FastAPI backend application script
]


# ==============================
# üîπ DIRECTORY & FILE CREATION
# ==============================

def create_file_structure(file_list):
    """
    Creates directories and files based on the given list.
    
    - If a directory does not exist, it is created.
    - If a file does not exist or is empty, it is created.
    - Logs every operation to track what is being created.

    Parameters:
        file_list (list): List of file paths to be created.
    """

    for filepath in file_list:
        filepath = Path(filepath)  # ‚úÖ Convert string path to a `Path` object
        filedir, filename = os.path.split(filepath)  # ‚úÖ Extract directory and filename separately

        # ‚úÖ Ensure the parent directory exists before creating the file
        if filedir:
            os.makedirs(filedir, exist_ok=True)  # ‚úÖ Create directory if it does not exist
            logger.info(f"Creating the directory '{filedir}' for file: '{filename}'")

        # ‚úÖ Check if the file does not exist or is empty, then create it
        if not filepath.exists() or filepath.stat().st_size == 0:
            with open(filepath, 'w'):  # ‚úÖ Create an empty file
                pass  # No content is added, just initializing the file
            logger.info(f"Creating empty file: '{filepath}'")  # ‚úÖ Log file creation
        else:
            logger.info(f"'{filepath}' already exists")  # ‚úÖ Log if the file already exists

# ‚úÖ Run the file creation function
create_file_structure(list_of_files)

================================================================================
# PY FILE: setup.py
================================================================================



================================================================================
# PY FILE: src\student_performance\__init__.py
================================================================================



================================================================================
# PY FILE: src\student_performance\components\__init__.py
================================================================================



================================================================================
# PY FILE: src\student_performance\components\data_ingestion.py
================================================================================

import numpy as np
import pandas as pd
from src.student_performance.entity.config_entity import DataIngestionConfig
from src.student_performance.entity.artifact_entity import DataIngestionArtifact
from src.student_performance.exception.exception import StudentPerformanceError
from src.student_performance.logging import logger
from src.student_performance.utils.core import save_to_csv
from src.student_performance.dbhandler.base_handler import DBHandler


class DataIngestion:
    def __init__(self, ingestion_config: DataIngestionConfig, db_handler: DBHandler):
        try:
            self.ingestion_config = ingestion_config
            self.db_handler = db_handler
        except Exception as e:
            logger.exception("Failed to initialize DataIngestion class.")
            raise StudentPerformanceError(e, logger) from e

    def __fetch_raw_data(self) -> pd.DataFrame:
        try:
            with self.db_handler as handler:
                df = handler.load_from_source()
                logger.info(f"Fetched {len(df)} raw rows from data source.")
                return df
        except Exception as e:
            logger.exception("Failed to fetch raw data from source.")
            raise StudentPerformanceError(e, logger) from e

    def __clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        try:
            df_cleaned = df.drop(columns=["_id"], errors="ignore").copy()
            df_cleaned.replace({"na": np.nan}, inplace=True)
            logger.info("Raw DataFrame cleaned successfully.")
            return df_cleaned
        except Exception as e:
            logger.exception("Failed to clean raw DataFrame.")
            raise StudentPerformanceError(e, logger) from e

    def run_ingestion(self) -> DataIngestionArtifact:
        """Runs the data ingestion process."""
        try:
            logger.info("========== Starting Data Ingestion ==========")

            # Step 1: Fetch raw data
            logger.info("Step 1: Fetching raw data")
            raw_df = self.__fetch_raw_data()

            # Step 2: Save raw data
            logger.info("Step 2: Saving raw data")
            save_to_csv(
                raw_df,
                self.ingestion_config.raw_data_filepath,
                label="Raw Data",
            )

            # Step 3: Save raw data to dvc path
            logger.info("Step 3: Saving raw data to dvc path")
            save_to_csv(
                raw_df,
                self.ingestion_config.dvc_raw_filepath,
                label="Raw Data",
            )

            # Step 4: Clean raw data
            logger.info("Step 4: Cleaning raw data")
            cleaned_df = self.__clean_dataframe(raw_df)

            # Step 5: Save cleaned (ingested) data
            logger.info("Step 5: Saving cleaned (ingested) data")
            save_to_csv(
                cleaned_df,
                self.ingestion_config.ingested_data_filepath,
                label="Ingested Data",
            )

            logger.info("========== Data Ingestion Completed ==========")

            return DataIngestionArtifact(
                raw_artifact_path=self.ingestion_config.raw_data_filepath,
                ingested_data_filepath=self.ingestion_config.ingested_data_filepath,
                dvc_raw_filepath=self.ingestion_config.dvc_raw_filepath,
            )
        except Exception as e:
            logger.exception("Data ingestion pipeline execution failed.")
            raise StudentPerformanceError(e, logger) from e

================================================================================
# PY FILE: src\student_performance\components\data_transformation.py
================================================================================

from pathlib import Path
from typing import Tuple
import pandas as pd
from sklearn.model_selection import train_test_split

from src.student_performance.entity.config_entity import DataTransformationConfig
from src.student_performance.entity.artifact_entity import DataValidationArtifact, DataTransformationArtifact
from src.student_performance.logging import logger
from src.student_performance.exception.exception import StudentPerformanceError
from src.student_performance.utils.core import read_csv, save_object, save_array
from src.student_performance.data_processors.preprocessor_builder import PreprocessorBuilder
from src.student_performance.constants.constants import (
    X_TRAIN_LABEL, Y_TRAIN_LABEL,
    X_VAL_LABEL, Y_VAL_LABEL,
    X_TEST_LABEL, Y_TEST_LABEL
)


class DataTransformation:
    def __init__(self, transformation_config: DataTransformationConfig, validation_artifact: DataValidationArtifact):
        try:
            self.transformation_config = transformation_config
            self.validation_artifact = validation_artifact
            self.df = read_csv(validation_artifact.validated_filepath)
        except Exception as e:
            raise StudentPerformanceError(e, logger) from e

    def _split_features_and_target(self) -> Tuple[pd.DataFrame, pd.Series]:
        try:
            df = self.df.copy()
            X = df.drop(columns=self.transformation_config.target_column)
            y = df[self.transformation_config.target_column]
            return X, y
        except Exception as e:
            raise StudentPerformanceError(e, logger) from e

    def _split_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple:
        try:
            split_params = self.transformation_config.transformation_params.data_split
            stratify = y if split_params.stratify else None

            X_train, X_temp, y_train, y_temp = train_test_split(
                X, y,
                train_size=split_params.train_size,
                stratify=stratify,
                random_state=split_params.random_state
            )

            relative_test_size = split_params.test_size / (split_params.test_size + split_params.val_size)
            X_val, X_test, y_val, y_test = train_test_split(
                X_temp, y_temp,
                test_size=relative_test_size,
                stratify=y_temp if split_params.stratify else None,
                random_state=split_params.random_state
            )

            return X_train, X_val, X_test, y_train, y_val, y_test
        except Exception as e:
            raise StudentPerformanceError(e, logger) from e

    def _save_datasets(self, X_train, X_val, X_test, y_train, y_val, y_test):
        try:
            save_array(X_train, self.transformation_config.x_train_filepath, self.transformation_config.x_train_dvc_filepath, label=X_TRAIN_LABEL)
            save_array(y_train, self.transformation_config.y_train_filepath, self.transformation_config.y_train_dvc_filepath, label=Y_TRAIN_LABEL)
            save_array(X_val, self.transformation_config.x_val_filepath, self.transformation_config.x_val_dvc_filepath, label=X_VAL_LABEL)
            save_array(y_val, self.transformation_config.y_val_filepath, self.transformation_config.y_val_dvc_filepath, label=Y_VAL_LABEL)
            save_array(X_test, self.transformation_config.x_test_filepath, self.transformation_config.x_test_dvc_filepath, label=X_TEST_LABEL)
            save_array(y_test, self.transformation_config.y_test_filepath, self.transformation_config.y_test_dvc_filepath, label=Y_TEST_LABEL)
        except Exception as e:
            raise StudentPerformanceError(e, logger) from e

    def run_transformation(self) -> DataTransformationArtifact:
        try:
            logger.info("========== Starting Data Transformation ==========")

            # Step 1: Separate features and target
            X, y = self._split_features_and_target()

            # Step 2: Split data into train/val/test
            X_train, X_val, X_test, y_train, y_val, y_test = self._split_data(X, y)

            # Step 3: Build preprocessor pipelines for X and Y
            builder = PreprocessorBuilder(
                steps=self.transformation_config.transformation_params.steps,
                methods=self.transformation_config.transformation_params.methods,
            )
            x_processor, y_processor = builder.build()

            # Step 4: Fit and transform data
            X_train = x_processor.fit_transform(X_train)
            X_val = x_processor.transform(X_val)
            X_test = x_processor.transform(X_test)

            y_train = y_processor.fit_transform(y_train)
            y_val = y_processor.transform(y_val)
            y_test = y_processor.transform(y_test)

            # Step 5: Save X and Y processors
            save_object(x_processor, self.transformation_config.x_preprocessor_filepath, label="X Preprocessor Pipeline")
            save_object(y_processor, self.transformation_config.y_preprocessor_filepath, label="Y Preprocessor Pipeline")

            # Step 6: Save transformed datasets
            self._save_datasets(X_train, X_val, X_test, y_train, y_val, y_test)

            logger.info("========== Data Transformation Completed ==========")

            return DataTransformationArtifact(
                x_train_filepath=self.transformation_config.x_train_filepath,
                y_train_filepath=self.transformation_config.y_train_filepath,
                x_val_filepath=self.transformation_config.x_val_filepath,
                y_val_filepath=self.transformation_config.y_val_filepath,
                x_test_filepath=self.transformation_config.x_test_filepath,
                y_test_filepath=self.transformation_config.y_test_filepath,
                x_preprocessor_filepath=self.transformation_config.x_preprocessor_filepath,
                y_preprocessor_filepath=self.transformation_config.y_preprocessor_filepath,
            )

        except Exception as e:
            logger.error("Data transformation failed.")
            raise StudentPerformanceError(e, logger) from e

================================================================================
# PY FILE: src\student_performance\components\data_validation.py
================================================================================

import hashlib
import pandas as pd
from box import ConfigBox
from scipy.stats import ks_2samp
import sys

from src.student_performance.entity.config_entity import DataValidationConfig
from src.student_performance.entity.artifact_entity import DataIngestionArtifact, DataValidationArtifact
from src.student_performance.exception.exception import StudentPerformanceError
from src.student_performance.logging import logger
from src.student_performance.utils.core import (
    read_csv, save_to_csv, save_to_yaml
)
from src.student_performance.utils.timestamp import get_utc_timestamp


class DataValidation:
    """
    Validates input data using schema checks, missing value checks,
    duplicate removal, categorical value enforcement, and drift detection.
    Generates validation reports and outputs a DataValidationArtifact.
    """

    def __init__(self, validation_config: DataValidationConfig, ingestion_artifact: DataIngestionArtifact):
        """
        Initialize data validator with configuration and ingested data.
        Loads base data if drift detection is enabled.
        """
        try:
            logger.info("Initializing DataValidation component.")

            # Load validation schema and parameters
            self.validation_config = validation_config
            self.schema = self.validation_config.schema
            self.params = self.validation_config.validation_params

            # Load ingested data
            self.df = read_csv(ingestion_artifact.ingested_data_filepath)
            self.base_df = None
            self.drift_check_performed = False
            self.timestamp = get_utc_timestamp()

            # Load base data for drift comparison, if enabled
            if self.params.drift_detection.enabled and self.validation_config.dvc_validated_filepath.exists():
                self.base_df = read_csv(self.validation_config.dvc_validated_filepath)
                self.drift_check_performed = True

            # Prepare report templates
            self.report = ConfigBox(self.validation_config.report_template.copy())
            self.critical_checks = ConfigBox({k: False for k in self.report.check_results.critical_checks.keys()})
            self.non_critical_checks = ConfigBox({k: False for k in self.report.check_results.non_critical_checks.keys()})

        except Exception as e:
            raise StudentPerformanceError(e, logger) from e

    def __check_schema_hash(self):
        """
        Compare the hash of the expected schema with the actual schema from the dataset.
        """
        try:
            logger.info("Performing schema hash check.")

            # Compute expected hash
            expected = self.schema.columns
            expected_str = "|".join(f"{col}:{dtype}" for col, dtype in sorted(expected.items()))
            expected_hash = hashlib.md5(expected_str.encode()).hexdigest()

            # Compute current dataset hash
            current_str = "|".join(f"{col}:{self.df[col].dtype}" for col in sorted(self.df.columns))
            current_hash = hashlib.md5(current_str.encode()).hexdigest()

            self.critical_checks.schema_is_match = (expected_hash == current_hash)

            logger.info("Schema hash check passed." if self.critical_checks.schema_is_match else "Schema hash mismatch.")
        except Exception as e:
            logger.exception("Schema hash check failed.")
            self.critical_checks.schema_is_match = False
            raise StudentPerformanceError(e, logger) from e

    def __check_schema_structure(self):
        """
        Check if dataset columns structurally match expected schema.
        """
        try:
            logger.info("Performing schema structure check.")

            expected_cols = set(self.schema.columns.keys()) | {self.schema.target_column}
            actual_cols = set(self.df.columns)

            self.critical_checks.schema_is_match = (expected_cols == actual_cols)

            if not self.critical_checks.schema_is_match:
                logger.error(f"Schema structure mismatch: expected={expected_cols}, actual={actual_cols}")
        except Exception as e:
            logger.exception("Schema structure check failed.")
            self.critical_checks.schema_is_match = False
            raise StudentPerformanceError(e, logger) from e

    def __check_missing_values(self):
        """
        Checks for missing values in the dataset and logs a YAML report.
        """
        try:
            logger.info("Checking for missing values.")

            missing = self.df.isnull().sum().to_dict()
            missing["timestamp"] = self.timestamp

            save_to_yaml(missing, self.validation_config.missing_report_filepath, label="Missing Value Report")

            self.non_critical_checks.no_missing_values = not any(
                v > 0 for v in missing.values() if isinstance(v, (int, float))
            )

            logger.info("Missing value check passed." if self.non_critical_checks.no_missing_values else "Missing values detected.")
        except Exception as e:
            logger.exception("Missing value check failed.")
            self.non_critical_checks.no_missing_values = False
            raise StudentPerformanceError(e, logger) from e

    def __check_duplicates(self):
        """
        Removes duplicates and logs the number removed.
        """
        try:
            logger.info("Checking for duplicate rows.")

            before = len(self.df)
            self.df = self.df.drop_duplicates()
            after = len(self.df)

            duplicates_removed = before - after

            result = {
                "duplicate_rows_removed": duplicates_removed,
                "timestamp": self.timestamp
            }

            save_to_yaml(result, self.validation_config.duplicates_report_filepath, label="Duplicates Report")
            self.non_critical_checks.no_duplicate_rows = (duplicates_removed == 0)

            logger.info("Duplicate check passed." if duplicates_removed == 0 else f"{duplicates_removed} duplicates removed.")
        except Exception as e:
            logger.exception("Duplicate check failed.")
            self.non_critical_checks.no_duplicate_rows = False
            raise StudentPerformanceError(e, logger) from e

    def __check_categorical_values(self):
        """
        Checks whether categorical columns contain only allowed values.
        """
        try:
            logger.info("Checking categorical values against schema constraints.")

            allowed_values = self.schema.get("allowed_values", {})
            violations = {}

            for col, allowed in allowed_values.items():
                if col not in self.df.columns:
                    continue

                actual_values = set(self.df[col].dropna().unique())
                unexpected = actual_values - set(allowed)

                if unexpected:
                    violations[col] = {
                        "unexpected_values": sorted(list(unexpected)),
                        "expected_values": allowed
                    }

            result = {
                "violations_found": bool(violations),
                "details": violations,
                "timestamp": self.timestamp
            }

            save_to_yaml(result, self.validation_config.categorical_report_filepath, label="Categorical Values Report")
            self.non_critical_checks.categorical_values_match = not bool(violations)

            logger.info("Categorical values check passed." if not violations else "Categorical values mismatch found.")
        except Exception as e:
            logger.exception("Categorical value check failed.")
            self.non_critical_checks.categorical_values_match = False
            raise StudentPerformanceError(e, logger) from e

    def __check_data_drift(self):
        """
        Performs KS test between base and current datasets to detect drift.
        """
        try:
            logger.info("Performing data drift check.")

            drift_results = {
                "timestamp": self.timestamp,
                "drift_check_performed": False
            }

            if self.base_df is None:
                logger.info("Base data not available. Skipping drift check.")
                drift_results["reason"] = "Base dataset not found. Drift check skipped."
                save_to_yaml(drift_results, self.validation_config.drift_report_filepath, label="Drift Report")
                self.critical_checks.no_data_drift = True
                return

            drift_detected = False
            drift_results.update({
                "drift_check_performed": True,
                "drift_method": self.params.drift_detection.method,
                "columns": {}
            })

            for col in self.df.columns:
                if col not in self.base_df.columns:
                    continue

                _, p_value = ks_2samp(self.base_df[col], self.df[col])
                drift = p_value < self.params.drift_detection.p_value_threshold
                drift_results["columns"][col] = {"p_value": float(p_value), "drift": drift}

                if drift:
                    drift_detected = True

            drift_results["drift_detected"] = drift_detected
            save_to_yaml(drift_results, self.validation_config.drift_report_filepath, label="Drift Report")
            self.critical_checks.no_data_drift = not drift_detected

            logger.info("Drift check passed." if not drift_detected else "Drift detected in columns.")
        except Exception as e:
            logger.exception("Data drift check failed.")
            self.critical_checks.no_data_drift = False
            raise StudentPerformanceError(e, logger) from e

    def __generate_report(self) -> dict:
        """
        Generate a unified validation report from individual checks.
        """
        try:
            logger.info("Generating final validation report.")

            validation_status = all(self.critical_checks.values())
            non_critical_status = all(self.non_critical_checks.values())

            self.report.timestamp = self.timestamp
            self.report.validation_status = validation_status
            self.report.critical_passed = validation_status
            self.report.non_critical_passed = non_critical_status
            self.report.schema_check_type = self.params.schema_check.method

            if self.drift_check_performed:
                self.report.drift_check_method = self.params.drift_detection.method
            else:
                self.report.pop("drift_check_method", None)

            self.report.check_results.critical_checks = self.critical_checks.to_dict()
            self.report.check_results.non_critical_checks = self.non_critical_checks.to_dict()

            return self.report.to_dict()
        except Exception as e:
            logger.exception("Failed to generate validation report.")
            raise StudentPerformanceError(e, logger) from e

    def run_validation(self) -> DataValidationArtifact:
        """
        Executes all validation steps and returns a validation artifact.
        """
        try:
            logger.info("========== Starting Data Validation ==========")

            logger.info("Step 1: Performing schema check")
            if self.params.schema_check.method == "hash":
                self.__check_schema_hash()
            else:
                self.__check_schema_structure()

            logger.info("Step 2: Checking missing values")
            self.__check_missing_values()

            logger.info("Step 3: Checking for duplicates")
            self.__check_duplicates()

            logger.info("Step 4: Checking categorical column values")
            self.__check_categorical_values()

            if self.params.drift_detection.enabled:
                logger.info("Step 5: Performing drift check")
                self.__check_data_drift()

            logger.info("Step 6: Generating validation report")
            report = self.__generate_report()
            save_to_yaml(report, self.validation_config.validation_report_filepath, label="Validation Report")

            validation_passed = all(self.critical_checks.values())

            logger.info("Step 7: Saving validated data if validation passes")
            if validation_passed:
                save_to_csv(
                    self.df,
                    self.validation_config.validated_filepath,
                    self.validation_config.dvc_validated_filepath,
                    label="Validated Data"
                )
                logger.info("Validated data saved successfully.")
            else:
                logger.warning("Validation failed. Validated data not saved.")

            logger.info("========== Data Validation Completed ==========")

            return DataValidationArtifact(
                validated_filepath=self.validation_config.validated_filepath if validation_passed else None,
                validation_status=validation_passed
            )
        except Exception as e:
            logger.exception("Data validation process failed.")
            raise StudentPerformanceError(e, logger) from e

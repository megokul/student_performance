--- CODE DUMP | PART 4 of 4 ---


================================================================================
# PY FILE: src\student_performance\logging\__init__.py
================================================================================

"""
Centralized logger for the student_performance project.

Provides a reusable `logger` instance configured with:
- UTC timestamped log directory and file
- File + stream handlers
- DEBUG level logging by default
"""

import logging
from .app_logger import setup_logger

# Static logger name and level
LOGGER_NAME = "student_performance_logger"
LOG_LEVEL = logging.DEBUG

# Initialize logger once and share across the project
logger = setup_logger(name=LOGGER_NAME, level=LOG_LEVEL)

================================================================================
# PY FILE: src\student_performance\logging\app_logger.py
================================================================================

import logging
import sys
from io import BytesIO
from pathlib import Path

import boto3

from box import ConfigBox
from yaml import safe_load

from src.student_performance.constants.constants import (
    CONFIG_ROOT,
    CONFIG_FILENAME,
    LOGS_ROOT,
)
from src.student_performance.utils.timestamp import get_utc_timestamp


class LogHandler(logging.Handler):
    """
    Buffers all log lines in memory and, on each emit, PUTs the full buffer
    to S3 so that the object is always up-to-date. No local file is ever written.
    """
    def __init__(self, bucket: str, key: str, level: int = logging.NOTSET) -> None:
        super().__init__(level)
        self.bucket = bucket
        self.key = key
        self.buffer = BytesIO()
        self.s3 = boto3.client("s3")
        self.setFormatter(logging.Formatter(
            "[%(asctime)s] - %(levelname)s - %(module)s - %(message)s"
        ))

    def emit(self, record: logging.LogRecord) -> None:
        try:
            line = self.format(record) + "\n"
            self.buffer.write(line.encode("utf-8"))
            # rewind to beginning before upload
            self.buffer.seek(0)
            self.s3.put_object(
                Bucket=self.bucket,
                Key=self.key,
                Body=self.buffer.getvalue()
            )
            # move buffer pointer to end for next write
            self.buffer.seek(0, 2)
        except Exception:
            self.handleError(record)

def read_yaml(path_to_yaml: Path) -> ConfigBox:
    """
    Load a YAML file and return its contents as a ConfigBox for dot-access.

    Raises:
        StudentPerformanceError: If the file is missing, corrupted, or unreadable.
    """
    
    return ConfigBox(content)


def setup_logger(name: str = "app_logger", level: int = logging.DEBUG) -> logging.Logger:
    """
    Configure and return a logger that:
      - Always writes to stdout.
      - If local_enabled: writes to LOGS_ROOT/<ts>/<ts>.log on disk.
      - If s3_enabled: streams to S3 under s3://<bucket>/logs/<ts>/<ts>.log.
      - If both flags are True, does both.
    """
    # ensure UTF-8 on console
    sys.stdout.reconfigure(encoding="utf-8")
    timestamp = get_utc_timestamp()

    # load YAML as ConfigBox
    config_path = Path(CONFIG_ROOT) / CONFIG_FILENAME
    with config_path.open("r", encoding="utf-8") as file:
        config = ConfigBox(safe_load(file))

    # flags
    local_enabled = config.data_backup.local_enabled
    s3_enabled = config.data_backup.s3_enabled
    bucket = config.s3_handler.s3_bucket

    logger = logging.getLogger(name)
    logger.setLevel(level)

    # 1) Console handler (always)
    if not any(isinstance(h, logging.StreamHandler) and h.stream is sys.stdout
               for h in logger.handlers):
        ch = logging.StreamHandler(sys.stdout)
        ch.setLevel(level)
        ch.setFormatter(logging.Formatter(
            "[%(asctime)s] - %(levelname)s - %(module)s - %(message)s"
        ))
        logger.addHandler(ch)

    # 2) Local file handler
    if local_enabled:
        log_dir = Path(LOGS_ROOT) / timestamp
        log_dir.mkdir(parents=True, exist_ok=True)
        log_filepath = log_dir / f"{timestamp}.log"

        if not any(isinstance(h, logging.FileHandler)
                   and h.baseFilename == str(log_filepath)
                   for h in logger.handlers):
            fh = logging.FileHandler(log_filepath, encoding="utf-8")
            fh.setLevel(level)
            fh.setFormatter(logging.Formatter(
                "[%(asctime)s] - %(levelname)s - %(module)s - %(message)s"
            ))
            logger.addHandler(fh)

    # 3) S3 handler
    if s3_enabled and bucket:
        log_s3_key = f"{LOGS_ROOT}/{timestamp}/{timestamp}.log"
        if not any(isinstance(h, LogHandler) for h in logger.handlers):
            s3h = LogHandler(bucket=bucket, key=log_s3_key, level=level)
            logger.addHandler(s3h)

    return logger

================================================================================
# PY FILE: src\student_performance\pipeline\__init__.py
================================================================================



================================================================================
# PY FILE: src\student_performance\pipeline\prediction_pipeline.py
================================================================================

from pathlib import Path
import numpy as np

from src.student_performance.config.configuration import ConfigurationManager
from src.student_performance.dbhandler.s3_handler import S3Handler
from src.student_performance.components.model_prediction import ModelPrediction
from src.student_performance.exception.exception import StudentPerformanceError
from src.student_performance.logging import logger
from src.student_performance.utils.core import load_array


class PredictionPipeline:
    def __init__(self):
        try:
            logger.info("Initializing PredictionPipeline...")
            self.config_manager = ConfigurationManager()
        except Exception as e:
            raise StudentPerformanceError(e, "Failed to initialize PredictionPipeline.") from e

    def run_pipeline(self, input_data_file: Path | None = None, input_array: np.ndarray | None = None) -> np.ndarray:
        try:
            logger.info("========== Prediction Pipeline Started ==========")

            # Step 1: Load prediction configuration and backup handler
            prediction_config = self.config_manager.get_model_prediction_config()
            s3_config = self.config_manager.get_s3_handler_config()
            s3_handler = S3Handler(s3_config) if prediction_config.s3_enabled else None

            # Step 2: Initialize the model predictor
            predictor = ModelPrediction(
                prediction_config=prediction_config,
                backup_handler=s3_handler,
            )

            # Step 3: Prepare input data
            if input_array is not None:
                logger.info("Using directly provided input array for prediction.")
                X = input_array
            elif input_data_file is not None:
                logger.info(f"Loading input data from file: {input_data_file}")
                X = load_array(input_data_file, label="Input Data")
            else:
                raise StudentPerformanceError("No input data provided for prediction.", logger)

            # Step 4: Run prediction
            predictions = predictor.predict(X)

            # Step 5: Save predictions to local/S3
            predictor.save_predictions(predictions)

            logger.info("========== Prediction Pipeline Completed ==========")
            return predictions

        except Exception as e:
            raise StudentPerformanceError(e, "PredictionPipeline failed.") from e

================================================================================
# PY FILE: src\student_performance\pipeline\training_pipeline.py
================================================================================

from src.student_performance.config.configuration import ConfigurationManager
from src.student_performance.exception.exception import StudentPerformanceError
from src.student_performance.dbhandler.postgres_dbhandler import PostgresDBHandler
from src.student_performance.dbhandler.s3_handler import S3Handler
from src.student_performance.logging import logger

from src.student_performance.components.data_ingestion import DataIngestion
from src.student_performance.components.data_validation import DataValidation
from src.student_performance.components.data_transformation import DataTransformation
from src.student_performance.components.model_trainer import ModelTrainer
from src.student_performance.components.model_evaluation import ModelEvaluation  # ✅ add import


class TrainingPipeline:
    def __init__(self):
        try:
            logger.info("Initializing TrainingPipeline...")
            self.config_manager = ConfigurationManager()
        except Exception as e:
            raise StudentPerformanceError(e, "Failed to initialize TrainingPipeline.") from e

    def run_pipeline(self):
        try:
            logger.info("========== Training Pipeline Started ==========")

            # Step 1: Setup configurations and database handler
            postgres_config = self.config_manager.get_postgres_handler_config()
            s3_config = self.config_manager.get_s3_handler_config()
            data_ingestion_config = self.config_manager.get_data_ingestion_config()
            postgresdb_handler = PostgresDBHandler(config=postgres_config)
            s3_handler = S3Handler(config=s3_config)

            # Step 2: Run data ingestion
            data_ingestion = DataIngestion(
                ingestion_config=data_ingestion_config,
                source_handler=postgresdb_handler,
                backup_handler=s3_handler,
            )
            data_ingestion_artifact = data_ingestion.run_ingestion()
            logger.info(f"Data Ingestion Artifact: {data_ingestion_artifact}")

            # Step 3: Run data validation
            data_validation_config = self.config_manager.get_data_validation_config()
            data_validation = DataValidation(
                validation_config=data_validation_config,
                ingestion_artifact=data_ingestion_artifact,
                backup_handler=s3_handler,
            )
            data_validation_artifact = data_validation.run_validation()
            logger.info(f"Data Validation Artifact: {data_validation_artifact}")

            # Step 4: Run data transformation
            if data_validation_artifact.validation_status:
                data_transformation_config = self.config_manager.get_data_transformation_config()
                data_transformation = DataTransformation(
                    transformation_config=data_transformation_config,
                    validation_artifact=data_validation_artifact,
                    backup_handler=s3_handler,
                )
                data_transformation_artifact = data_transformation.run_transformation()
                logger.info(f"Data Transformation Artifact: {data_transformation_artifact}")
            else:
                logger.warning("Data validation failed. Skipping data transformation.")
                return

            # Step 5: Run model training
            model_trainer_config = self.config_manager.get_model_trainer_config()
            model_trainer = ModelTrainer(
                trainer_config=model_trainer_config,
                transformation_artifact=data_transformation_artifact,
                backup_handler=s3_handler,
            )
            model_trainer_artifact = model_trainer.run_training()
            logger.info(f"Model Trainer Artifact: {model_trainer_artifact}")

            # Step 6: Run model evaluation
            model_evaluation_config = self.config_manager.get_model_evaluation_config()
            model_evaluation = ModelEvaluation(
                evaluation_config=model_evaluation_config,
                trainer_artifact=model_trainer_artifact,
                backup_handler=s3_handler,
            )
            model_evaluation_artifact = model_evaluation.run_evaluation()
            logger.info(f"Model Evaluation Artifact: {model_evaluation_artifact}")

            logger.info("========== Training Pipeline Completed ==========")

        except Exception as e:
            raise StudentPerformanceError(e, "TrainingPipeline failed.") from e

================================================================================
# PY FILE: src\student_performance\utils\__init__.py
================================================================================



================================================================================
# PY FILE: src\student_performance\utils\core.py
================================================================================

import pandas as pd
from pathlib import Path
from box import ConfigBox
from box.exceptions import BoxValueError, BoxTypeError, BoxKeyError
from ensure import ensure_annotations
import yaml
import json
import numpy as np
import pandas as pd
import joblib

from src.student_performance.logging import logger
from src.student_performance.exception.exception import StudentPerformanceError


@ensure_annotations
def read_yaml(path_to_yaml: Path) -> ConfigBox:
    """
    Load a YAML file and return its contents as a ConfigBox for dot-access.

    Raises:
        StudentPerformanceError: If the file is missing, corrupted, or unreadable.
    """
    if not path_to_yaml.exists():
        msg = f"YAML file not found: '{path_to_yaml}'"
        raise StudentPerformanceError(FileNotFoundError(msg), msg)

    try:
        with path_to_yaml.open("r", encoding="utf-8") as file:
            content = yaml.safe_load(file)
    except (BoxValueError, BoxTypeError, BoxKeyError, yaml.YAMLError) as e:
        msg = f"Failed to parse YAML from: '{path_to_yaml.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e
    except Exception as e:
        msg = f"Unexpected error while reading YAML from: '{path_to_yaml.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e

    if content is None:
        msg = f"YAML file is empty or improperly formatted: '{path_to_yaml}'"
        raise StudentPerformanceError(ValueError(msg), msg)

    logger.info(f"YAML successfully loaded from: '{path_to_yaml.as_posix()}'")
    return ConfigBox(content)


@ensure_annotations
def save_to_csv(df: pd.DataFrame, *paths: Path, label: str):
    try:
        for path in paths:
            path = Path(path)
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created directory for {label}: '{path.parent.as_posix()}'")
            else:
                logger.info(f"Directory already exists for {label}: '{path.parent.as_posix()}'")

            df.to_csv(path, index=False)
            logger.info(f"{label} saved to: '{path.as_posix()}'")
    except Exception as e:
        msg = f"Failed to save CSV to: '{path.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e


@ensure_annotations
def read_csv(filepath: Path) -> pd.DataFrame:
    """
    Read a CSV file into a Pandas DataFrame.

    Raises:
        StudentPerformanceError: If the file is missing, corrupted, or unreadable.
    """
    if not filepath.exists():
        msg = f"CSV file not found: '{filepath}'"
        raise StudentPerformanceError(FileNotFoundError(msg), msg)

    try:
        df = pd.read_csv(filepath)
        logger.info(f"CSV file read successfully from: '{filepath.as_posix()}'")
        return df
    except Exception as e:
        msg = f"Failed to read CSV from: '{filepath.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e

@ensure_annotations
def save_to_yaml(data: dict, *paths: Path, label: str):
    """
    Write a dict out to YAML, always using UTF-8.
    """
    try:
        for path in paths:
            path = Path(path)
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created directory for {label}: '{path.parent.as_posix()}'")
            else:
                logger.info(f"Directory already exists for {label}: '{path.parent.as_posix()}'")

            # Write UTF-8
            with open(path, "w", encoding="utf-8") as file:
                yaml.dump(data, file, sort_keys=False)

            logger.info(f"{label} saved to: '{path.as_posix()}'")
    except Exception as e:
        msg = f"Failed to read CSV from: '{path.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e

@ensure_annotations
def save_to_json(data: dict, *paths: Path, label: str):
    try:
        for path in paths:
            path = Path(path)
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created directory for {label}: '{path.parent.as_posix()}'")
            else:
                logger.info(f"Directory already exists for {label}: '{path.parent.as_posix()}'")

            with open(path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4)

            logger.info(f"{label} saved to: '{path.as_posix()}'")
    except Exception as e:
        msg = f"Failed to read CSV from: '{path.as_posix()}' — {e}"
        raise StudentPerformanceError(e, msg) from e


@ensure_annotations
def save_object(obj: object, *paths: Path, label: str):
    """
    Saves a serializable object using joblib to the specified path.

    Args:
        obj (object): The object to serialize.
        path (Path): The path to save the object.
        label (str): Label used for logging context.
    """
    try:
        for path in paths:
            path = Path(path)
            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created directory for {label}: '{path.parent.as_posix()}'")
            else:
                logger.info(f"Directory already exists for {label}: '{path.parent.as_posix()}'")

            joblib.dump(obj, path)
            logger.info(f"{label} saved to: '{path.as_posix()}'")

    except Exception as e:
        msg = f"Failed to save {label} to: '{path.as_posix()}'"
        raise StudentPerformanceError(e, logger) from e


@ensure_annotations
def save_array(array: np.ndarray | pd.Series, *paths: Path, label: str):
    """
    Saves a NumPy array or pandas Series to the specified paths in `.npy` format.

    Args:
        array (Union[np.ndarray, pd.Series]): Data to save.
        *paths (Path): One or more file paths.
        label (str): Label for logging.
    """
    try:
        array = np.asarray(array)

        for path in paths:
            path = Path(path)

            if not path.parent.exists():
                path.parent.mkdir(parents=True, exist_ok=True)
                logger.info(f"Created directory for {label}: '{path.parent.as_posix()}'")
            else:
                logger.info(f"Directory already exists for {label}: '{path.parent.as_posix()}'")

            np.save(path, array)
            logger.info(f"{label} saved to: '{path.as_posix()}'")

    except Exception as e:
        msg = f"Failed to save {label} to: '{path.as_posix()}'"
        raise StudentPerformanceError(e, logger) from e


@ensure_annotations
def load_array(path: Path, label: str) -> np.ndarray:
    """
    Loads a NumPy array from the specified `.npy` file path.

    Args:
        path (Path): Path to the `.npy` file.
        label (str): Label for logging.

    Returns:
        np.ndarray: Loaded NumPy array.
    """
    try:
        path = Path(path)

        if not path.exists():
            raise FileNotFoundError(f"{label} file not found at path: '{path.as_posix()}'")

        array = np.load(path)
        logger.info(f"{label} loaded successfully from: '{path.as_posix()}'")
        return array

    except Exception as e:
        msg = f"Failed to load {label} from: '{path.as_posix()}'"
        raise StudentPerformanceError(e, logger) from e

@ensure_annotations
def load_object(path: Path, label: str):
    """
    Loads a serialized object from the specified path using joblib.

    Args:
        path (Path): The path to the serialized object.
        label (str): Label used for logging context.

    Returns:
        Any: The deserialized object.
    """
    try:
        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f"{label} not found at: '{path.as_posix()}'")
        obj = joblib.load(path)
        logger.info(f"{label} loaded from: '{path.as_posix()}'")
        return obj

    except Exception as e:
        msg = f"Failed to load {label} from: '{path.as_posix()}'"
        logger.exception(msg)
        raise StudentPerformanceError(e, logger) from e

================================================================================
# PY FILE: src\student_performance\utils\timestamp.py
================================================================================

from datetime import datetime, timezone

_timestamp_cache: str | None = None

def get_utc_timestamp() -> str:
    format="%Y_%m_%dT%H_%M_%SZ"
    global _timestamp_cache
    if _timestamp_cache is None:
        _timestamp_cache = datetime.now(timezone.utc).strftime(format)
    return _timestamp_cache

================================================================================
# YAML FILE: config\config.yaml
================================================================================

# Data ingestion configuration
data_ingestion:
  raw_data_filename: raw.csv
  ingested_data_filename: ingested_data.csv

# Data validation configuration
data_validation:
  validated_data_filename: validated_data.csv
  missing_report_filename: missing_values_report.yaml
  duplicates_report_filename: duplicates_report.yaml
  drift_report_filename: drift_report.yaml
  validation_report_filename: validation_report.yaml
  categorical_report_filename: categorical_report.yaml

# Data transformation configuration
data_transformation:
  x_train_filename: x_train.npy
  y_train_filename: y_train.npy
  x_val_filename: x_val.npy
  y_val_filename: y_val.npy
  x_test_filename: x_test.npy
  y_test_filename: y_test.npy
  x_preprocessor_filename: x_preprocessor.joblib
  y_preprocessor_filename: y_preprocessor.joblib

# Model trainer configuration
model_trainer:
  model_dir: saved_models
  inference_model_filename: inference_model.joblib
  trained_model_filename: model.joblib
  training_report_filename: training_report.yaml

model_evaluation:
  report_filename: evaluation_report.yaml

# PostGres configuration
postgres_dbhandler:
  input_data_dir: student_data
  input_data_filename: stud.csv
  dbname: student_performance_db
  table_name: student_scores

s3_handler:
  s3_bucket: studentperformance-dev-artifacts
  s3_inference_model_prefix: inference_model
  s3_artifacts_prefix: artifacts
  
data_backup:
  s3_enabled: true
  local_enabled: true

================================================================================
# YAML FILE: config\params.yaml
================================================================================

# Parameters for drift detection during data validation
validation_params:
  drift_detection:
    enabled: true
    method: ks_test
    p_value_threshold: 0.05

  schema_check:
    enabled: true
    method: hash

transformation_params:
  data_split:
    train_size: 0.6
    val_size: 0.2
    test_size: 0.2
    random_state: 42
    stratify: false

  steps:
    x:
      - encoding
    y:
      - column_math

  methods:
    x:
      column_operation:
        method: remove_col
        columns:
          - id
      encoding:
        method: one_hot
        handle_unknown: ignore
        columns:
          - gender
          - race_ethnicity
          - parental_level_of_education
          - lunch
          - test_preparation_course

      standardization:
        method: standard_scaler
        with_mean: false
        with_std: true

    y:
      column_math:
        method: mean_of_columns
        output_column: mean_score
        inplace: True
        input_column:
          - math_score
          - reading_score
          - writing_score

      standardization:
        method: standard_scaler
        with_mean: true
        with_std: true

model_trainer:
  models:
    - name: sklearn.ensemble.RandomForestRegressor
      params:
        n_estimators: 100
        max_depth: 10
        random_state: 42
      search_space:
        n_estimators:
          distribution: int
          low: 50
          high: 300
          step: 10
        max_depth:
          distribution: int
          low: 5
          high: 50
          step: 1

    - name: sklearn.ensemble.GradientBoostingRegressor
      params:
        n_estimators: 100
        learning_rate: 0.1
        max_depth: 3
        random_state: 42
      search_space:
        n_estimators:
          distribution: int
          low: 50
          high: 200
          step: 10
        learning_rate:
          distribution: float
          low: 0.01
          high: 1.0
          log: true
        max_depth:
          distribution: int
          low: 2
          high: 10

  optimization:
    enabled: true
    method: optuna
    n_trials: 30
    direction: maximize
    cv_folds: 5
    scoring: neg_root_mean_squared_error

tracking:
  mlflow:
    enabled: true
    experiment_name: StudentPerformanceExperiment
    registry_model_name: StudentPerformanceModel
    metrics_to_log:
      - neg_root_mean_squared_error
      - r2
      - neg_mean_absolute_error
      - neg_mean_squared_error
      - adjusted_r2
    log_trials: false
  
model_evaluation:
  metrics:
    - mean_absolute_error
    - mean_squared_error
    - root_mean_squared_error
    - r2
    - adjusted_r2
    - median_absolute_error
    - explained_variance_score

================================================================================
# YAML FILE: config\schema.yaml
================================================================================

table_schema:
  student_scores:
    columns:
      id:
        type: "SERIAL PRIMARY KEY"

      gender:
        type: "VARCHAR(10)"
        constraints:
          allowed_values:
            - "male"
            - "female"

      race_ethnicity:
        type: "VARCHAR(20)"
        constraints:
          allowed_values:
            - "group A"
            - "group B"
            - "group C"
            - "group D"
            - "group E"

      parental_level_of_education:
        type: "VARCHAR(50)"
        constraints:
          allowed_values:
            - "some high school"
            - "high school"
            - "associate's degree"
            - "some college"
            - "bachelor's degree"
            - "master's degree"

      lunch:
        type: "VARCHAR(20)"
        constraints:
          allowed_values:
            - "standard"
            - "free/reduced"

      test_preparation_course:
        type: "VARCHAR(20)"
        constraints:
          allowed_values:
            - "none"
            - "completed"

      math_score:
        type: "INT"
        constraints:
          min: 0
          max: 100

      reading_score:
        type: "INT"
        constraints:
          min: 0
          max: 100

      writing_score:
        type: "INT"
        constraints:
          min: 0
          max: 100

validation_schema:
  columns:
    id: int64
    gender: object
    race_ethnicity: object
    parental_level_of_education: object
    lunch: object
    test_preparation_course: object
    math_score: int64
    reading_score: int64
    writing_score: int64

  allowed_values:
    gender:
      - male
      - female
    race_ethnicity:
      - group A
      - group B
      - group C
      - group D
      - group E
    parental_level_of_education:
      - some high school
      - high school
      - some college
      - associate's degree
      - bachelor's degree
      - master's degree
    lunch:
      - standard
      - free/reduced
    test_preparation_course:
      - none
      - completed

target_column:
  - math_score
  - reading_score
  - writing_score

================================================================================
# YAML FILE: config\templates.yaml
================================================================================

validation_report:
  timestamp: ""
  
  validation_status: null
  critical_passed: null
  non_critical_passed: null

  schema_check_type: ""
  drift_check_method: ""

  check_results:
    critical_checks:
      schema_is_match: null
      no_data_drift: null

    non_critical_checks:
      no_missing_values: null
      no_duplicate_rows: null
